wandb:
  project: BlumNetGraph
  name: blumnet_refactor_2
  dir: "tmp"
# General parameters
device: cuda
seed: 42
load_path: "pretrain"
eval_score: 0.65
output_dir: "tmp/checkpoints"

# Optimizer parameters
lr: 0.0002
lr_backbone: 0.00002
lr_linear_proj_mult: 0.1
weight_decay: 0.0001
lr_drop: 160
clip_max_norm: 0.1
# Training parameters
batch_size: 1
epochs: 40
num_workers: 2
eval_epochs: 8
t_0: 41
t_mult: 2
# Backbone parameters
backbone: swin_small
dilation: false
position_embedding: sine
position_embedding_scale: 6.283185307179586
num_feature_levels: 3
lr_backbone_names: ["backbone.0"]
lr_linear_proj_names: ["reference_points", "sampling_offsets"]

# Transformer parameters
enc_layers: 6
dec_layers: 6
dim_feedforward: 1024
hidden_dim: 256
dropout: 0.1
nheads: 8
num_queries: 1024
points_per_path: 2
dec_n_points: 8
enc_n_points: 8

# Output parameters
out_pts: 128
aux_loss: false

# Matcher parameters
set_cost_class: 1
set_cost_bbox: 5
cls_loss_coef: 1
bbox_loss_coef: 5
focal_alpha: 0.25
pts_loss_coef: 1

# Using the same num_queries as transformer
with_box_refine: false
frozen_weights: null

# Dataset parameters
rule: overlap_10_0.6
data_root: "data"
train_split: "data/sk1491/train/train_pair.lst"
test_split: "data/sk1491/test/test_pair.lst"
random_rotate: False

# Visualization parameters
visual_type: lines